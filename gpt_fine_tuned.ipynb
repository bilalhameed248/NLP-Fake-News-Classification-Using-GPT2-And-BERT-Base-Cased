{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9e3db5b8f1142f9bc3dbc579fc14187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d7229b1dec5407689815854ab0a88cf",
              "IPY_MODEL_d7a89f25bd86438c9aea3b06ad89a41b",
              "IPY_MODEL_d294e377bfe4407c948a57fe6e80cb24"
            ],
            "layout": "IPY_MODEL_69244b515bc04987800872f4c9f5a808"
          }
        },
        "6d7229b1dec5407689815854ab0a88cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea9a18fa20894d5eb8da79de8b77f649",
            "placeholder": "​",
            "style": "IPY_MODEL_074495d5f57c4b03b682273f294e3931",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "d7a89f25bd86438c9aea3b06ad89a41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6afcaea34bcb4a95a683aaf964ea6156",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f112f36791a54d9bb67bdc543d7e6a46",
            "value": 548118077
          }
        },
        "d294e377bfe4407c948a57fe6e80cb24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43616cce38a8474da768b7926f147c3b",
            "placeholder": "​",
            "style": "IPY_MODEL_602d7cc0be6e404bbbfe97a230c6ea47",
            "value": " 523M/523M [00:11&lt;00:00, 51.3MB/s]"
          }
        },
        "69244b515bc04987800872f4c9f5a808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea9a18fa20894d5eb8da79de8b77f649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "074495d5f57c4b03b682273f294e3931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6afcaea34bcb4a95a683aaf964ea6156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f112f36791a54d9bb67bdc543d7e6a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43616cce38a8474da768b7926f147c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "602d7cc0be6e404bbbfe97a230c6ea47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Text Classification using fine-tuned GPT-2 model"
      ],
      "metadata": {
        "id": "aYve9sCF_FH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import packages"
      ],
      "metadata": {
        "id": "kbFHeQTb_QZc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z34Gyht8r0CA"
      },
      "outputs": [],
      "source": [
        "# !pip3 install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchaudio==0.10.2+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "# !pip3 install pandas\n",
        "# !pip3 install numpy\n",
        "# !pip3 install sklearn\n",
        "# !pip3 install tqdm\n",
        "# !pip3 install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from transformers import GPT2Model, GPT2Tokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "rmlhOzrmr3uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Google Drive\n",
        "here i also create folder in my drive with name ColabNotebooks"
      ],
      "metadata": {
        "id": "q-Rhsqku_VEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usbDqL6Rs4om",
        "outputId": "88d80ac7-c6b0-4256-e0f8-a8b36f2b7228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/ColabNotebooks/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeodH767s7Dv",
        "outputId": "bfd3c674-381f-4f8d-89a9-b7ee377e2625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/ColabNotebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Read data from drive into dataframe"
      ],
      "metadata": {
        "id": "5eb4tzql_pca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "iIzuisWKt_1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./train_df.csv')\n",
        "# df = pd.read_csv('./bbc-text.csv')"
      ],
      "metadata": {
        "id": "UgFxoSUquB8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "addwjnhOuCYj",
        "outputId": "83039c01-4985-4f78-9f4d-f5861c31a142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      0  We were greeted in an inquisitive but friendly...\n",
              "1      0  In the flat below , a teenage couple quarrelle...\n",
              "2      0  The phrase '' Protocols-style '' carries a cri...\n",
              "3      0  By its light Rachaela saw Adamus lie Ruth on h...\n",
              "4      0   Widowed at twenty-two , left with a small baby ."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5efbac1f-0f3c-4521-9aaa-7cb275b912d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>We were greeted in an inquisitive but friendly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>In the flat below , a teenage couple quarrelle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>The phrase '' Protocols-style '' carries a cri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>By its light Rachaela saw Adamus lie Ruth on h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Widowed at twenty-two , left with a small baby .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5efbac1f-0f3c-4521-9aaa-7cb275b912d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5efbac1f-0f3c-4521-9aaa-7cb275b912d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5efbac1f-0f3c-4521-9aaa-7cb275b912d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change Column type from int to Obj"
      ],
      "metadata": {
        "id": "VxSjldrN_vS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.astype(str)\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7PfnhQw6Z-E",
        "outputId": "0fb06b09-0df3-496d-ba4d-3ac290ad7723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label    object\n",
            "text     object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"label\").size().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "i-Ki3pkeuJoi",
        "outputId": "662b9584-ec32-45c9-9944-00d4efc91b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4f860d2e90>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing data (text tokenization)"
      ],
      "metadata": {
        "id": "rd6-M4ac_3c7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to tokenize the input text in order to feed GPT-2 model with its expected data format. This can be easily done using HuggingFace Transformers' GPT2Tokenizer object. However, unlike BERT which does padding to the right, for GPT-2 we need to do padding to the left, because we need to use the last token for prediction. Therefore we need to adapt GPT2Tokenizer after calling."
      ],
      "metadata": {
        "id": "VG6s5vuW_9Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "qO0y6mUBuN2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = \"I will watch Memento tonight\"\n",
        "gpt2_input = tokenizer(example_text, padding=\"max_length\", max_length=10, truncation=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "kZyIyj6auQa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt2_input['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpy-u1sYuTFz",
        "outputId": "69e9741b-d68e-4390-e87c-18d6e44dbe46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256, 50256, 50256,    40,   481,  2342,   337,   972,    78,  9975]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt2_input[\"attention_mask\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h6jB9Z8uUmN",
        "outputId": "4554f9d1-5920-4420-e8da-879ed59b3845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tokenizer.decode(gpt2_input.input_ids[0])\n",
        "print(example_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNHO5YwbuWAs",
        "outputId": "78aa88e8-883b-422e-ecb5-c54bd8397a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|><|endoftext|><|endoftext|>I will watch Memento tonight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset class"
      ],
      "metadata": {
        "id": "mRdsZz2wALLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will build a custom Dataset class to read in our news data, tokenize them, and store them into containers for batch training using PyTorch."
      ],
      "metadata": {
        "id": "hfy_VZTRASnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "labels = {\n",
        "    \"0\": 0,\n",
        "    \"1\": 1\n",
        "         }\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.labels = [labels[label] for label in df['label']]\n",
        "        self.texts = [tokenizer(text,\n",
        "                                padding='max_length',\n",
        "                                max_length=128,\n",
        "                                truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "        \n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def get_batch_labels(self, idx):\n",
        "        # Get a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "    \n",
        "    def get_batch_texts(self, idx):\n",
        "        # Get a batch of inputs\n",
        "        return self.texts[idx]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "6kHWZTtkuX1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split training-test dataset"
      ],
      "metadata": {
        "id": "ChqiESLqAg8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One more thing to do before we start with models. We need to split train, validation and test data as separate dataframes. Numpy's split function can do just that."
      ],
      "metadata": {
        "id": "lB7uClovAkgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=35),\n",
        "                                     [int(0.8*len(df)), int(0.9*len(df))])\n",
        "\n",
        "print(len(df_train), len(df_val), len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw4rFxvrujPl",
        "outputId": "caf89e4c-0d60-4c4f-e4a1-f50eb346c5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1612 202 202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model building Code"
      ],
      "metadata": {
        "id": "mHB_z7eeArYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to buid a classifier model on top of a pre-trained GPT-2 model. The trick here is to add a linear layer on top of GPT-2's 12 layers of decoders with its output dimension equals our number of labels. In this way we can use GPT-2 to output 2 numbers which corresponds to our five news categories!"
      ],
      "metadata": {
        "id": "L35eHUjMAzaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleGPT2SequenceClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size: int, num_classes:int ,max_seq_len:int, gpt_model_name:str):\n",
        "        super(SimpleGPT2SequenceClassifier,self).__init__()\n",
        "        self.gpt2model = GPT2Model.from_pretrained(gpt_model_name)\n",
        "        self.fc1 = nn.Linear(hidden_size*max_seq_len, num_classes)\n",
        "\n",
        "        \n",
        "    def forward(self, input_id, mask):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "                input_id: encoded inputs ids of sent.\n",
        "        \"\"\"\n",
        "        gpt_out, _ = self.gpt2model(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
        "        batch_size = gpt_out.shape[0]\n",
        "        linear_output = self.fc1(gpt_out.view(batch_size,-1))\n",
        "        return linear_output"
      ],
      "metadata": {
        "id": "fkbWR0VBu67X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "zRtIhnOHA3fM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to train (fine-tune) our model! Here I build a standard PyTorch training loop following this guide. Since this is a multi-class classification problem, I picked cross-entropy-loss as our loss function (\"criterion\"), and Adam as the optimization algorithm and using training epoch as 1 you can set it to 3 5  etc as per your choice. "
      ],
      "metadata": {
        "id": "AjlZAHnmA7AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "    \n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "    \n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "        \n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_input['attention_mask'].to(device)\n",
        "            input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
        "            \n",
        "            model.zero_grad()\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "            \n",
        "            batch_loss = criterion(output, train_label)\n",
        "            total_loss_train += batch_loss.item()\n",
        "            \n",
        "            acc = (output.argmax(dim=1)==train_label).sum().item()\n",
        "            total_acc_train += acc\n",
        "\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            \n",
        "            for val_input, val_label in val_dataloader:\n",
        "                val_label = val_label.to(device)\n",
        "                mask = val_input['attention_mask'].to(device)\n",
        "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "                \n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                batch_loss = criterion(output, val_label)\n",
        "                total_loss_val += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1)==val_label).sum().item()\n",
        "                total_acc_val += acc\n",
        "                \n",
        "            print(\n",
        "            f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train/len(train_data): .3f} \\\n",
        "            | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "            | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "            | Val Accuracy: {total_acc_val / len(val_data): .3f}\")\n",
        "            \n",
        "EPOCHS = 1\n",
        "model = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes=2, max_seq_len=128, gpt_model_name=\"gpt2\")\n",
        "LR = 1e-5\n",
        "\n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "c9e3db5b8f1142f9bc3dbc579fc14187",
            "6d7229b1dec5407689815854ab0a88cf",
            "d7a89f25bd86438c9aea3b06ad89a41b",
            "d294e377bfe4407c948a57fe6e80cb24",
            "69244b515bc04987800872f4c9f5a808",
            "ea9a18fa20894d5eb8da79de8b77f649",
            "074495d5f57c4b03b682273f294e3931",
            "6afcaea34bcb4a95a683aaf964ea6156",
            "f112f36791a54d9bb67bdc543d7e6a46",
            "43616cce38a8474da768b7926f147c3b",
            "602d7cc0be6e404bbbfe97a230c6ea47"
          ]
        },
        "id": "VCAwHEzZu93M",
        "outputId": "542748b9-23d8-48a9-def7-aca24dea50e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/523M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9e3db5b8f1142f9bc3dbc579fc14187"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 806/806 [51:58<00:00,  3.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.243             | Train Accuracy:  0.782             | Val Loss:  0.349             | Val Accuracy:  0.767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Looks* like the model is already well trained after 1 epoch! This is probably due to the fact that as a pre-trained model with gigantic number of parameters, GPT-2 is already capable of differentiating different text paragraphs without too much tuning."
      ],
      "metadata": {
        "id": "IGL712lpBfCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "After model training, it's recommended to use the test data to evaluate the model performance on unseen data. I build the evaluate function according this PyTorch guide."
      ],
      "metadata": {
        "id": "n2Rgl0uUBmqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "        \n",
        "    # Tracking variables\n",
        "    predictions_labels = []\n",
        "    true_labels = []\n",
        "    \n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "            test_label = test_label.to(device)\n",
        "            mask = test_input['attention_mask'].to(device)\n",
        "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "\n",
        "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "            total_acc_test += acc\n",
        "            \n",
        "            # add original labels\n",
        "            true_labels += test_label.cpu().numpy().flatten().tolist()\n",
        "            # get predicitons to list\n",
        "            predictions_labels += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
        "    return true_labels, predictions_labels\n",
        "    \n",
        "true_labels, pred_labels = evaluate(model, df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9M-fpQvuGcG",
        "outputId": "e01164df-6da7-499c-da87-da5b0cc21805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we got 75 % acc with just 1 epochs you can try 3 epocs and your model will return 95 % accuracy. i use i epoch because i have less cpu and ram"
      ],
      "metadata": {
        "id": "GYLx-rWIByzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another good gauge of model performance is the confusion matrix."
      ],
      "metadata": {
        "id": "fABdJQP9BuwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Uma523UrBwmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix.\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels, labels=range(len(labels)), normalize='true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(labels.keys()))\n",
        "disp.plot(ax=ax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "nmz6b_ifuQn7",
        "outputId": "4beb613a-432f-439a-f14a-af7c0fdd87a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fa74f208690>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading the model"
      ],
      "metadata": {
        "id": "aM8uSc15CEnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training, we need to save the model locally. PyTorch models store the learned parameters in an internal state dictionary, called state_dict. These can be persisted via the torch.save method:"
      ],
      "metadata": {
        "id": "AiTElxU8CLCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save trained model\n",
        "torch.save(model.state_dict(), \"./gpt_model/gpt2-text-classifier-model.pt\")"
      ],
      "metadata": {
        "id": "qD-I1dwX8Cgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load model weights, you need to create an instance of the same model first, and then load the parameters using load_state_dict() method"
      ],
      "metadata": {
        "id": "S9z2gw-uCSa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load trained model\n",
        "model_new = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes=2, max_seq_len=128, gpt_model_name=\"gpt2\")\n",
        "model_new.load_state_dict(torch.load(\"./gpt_model/gpt2-text-classifier-model.pt\"))\n",
        "model_new.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0owM6u848pEv",
        "outputId": "1f26c6cb-5921-4651-bb0d-c2a865f2f539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleGPT2SequenceClassifier(\n",
              "  (gpt2model): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=98304, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Inference"
      ],
      "metadata": {
        "id": "YdOxnvZSCeL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = \"\"\"\n",
        "A graduate scientist is required in the Measurement and Instrumentation Section to work on a range of projects concerning analysis of beer and its raw materials .\n",
        "\"\"\"\n",
        "fixed_text = \" \".join(example_text.lower().split())\n",
        "print(fixed_text)\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model_input = tokenizer(fixed_text, padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")\n",
        "print(model_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vWKv4ez9j8B",
        "outputId": "892997ff-3589-4348-8f72-0e72ea06baf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a graduate scientist is required in the measurement and instrumentation section to work on a range of projects concerning analysis of beer and its raw materials .\n",
            "{'input_ids': tensor([[50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "            64, 10428, 11444,   318,  2672,   287,   262, 15558,   290,  8875,\n",
            "           341,  2665,   284,   670,   319,   257,  2837,   286,  4493,  9305,\n",
            "          3781,   286,  6099,   290,   663,  8246,  5696,   764]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After text tokenization, we need to extract two inputs for the model, input_id and mask."
      ],
      "metadata": {
        "id": "NPnM1zp1Ckc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = model_input['attention_mask'].cpu()\n",
        "input_id = model_input[\"input_ids\"].squeeze(1).cpu()\n",
        "\n",
        "output = model_new(input_id, mask)"
      ],
      "metadata": {
        "id": "qqO6XCRV-F3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mask.shape)\n",
        "print(input_id.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2ZQypnwU290",
        "outputId": "d45d7c5c-8a7d-43d3-dfe6-d37e1778fd50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 128])\n",
            "torch.Size([1, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRX7T5B5-KMr",
        "outputId": "fbd572ef-f07c-4809-b61d-f4ac809a2a2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.3731, -2.6936]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output here is the model output for each label. We can normalize them as probabilities using Softmax algorithm."
      ],
      "metadata": {
        "id": "1vTOYbt3Cp_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob = torch.nn.functional.softmax(output, dim=1)[0]"
      ],
      "metadata": {
        "id": "UKIENdxD-Msj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prob)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PGQcpjs-Pse",
        "outputId": "36ef68e3-b690-4f0b-cd44-a7ad9d6d6525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9832, 0.0168], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see if our predictor can correctly classify this label 0/1"
      ],
      "metadata": {
        "id": "Ddcf2a1UCvDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"0\",\n",
        "    1: \"1\"\n",
        "         }\n",
        "\n",
        "pred_label = labels_map[output.argmax(dim=1).item()]\n",
        "print(pred_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65WaVM7P-RgM",
        "outputId": "88f5877c-4a4a-4ad4-82c4-94109394d38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_number_batches(input_length, batch_size):\n",
        "  if input_length % batch_size == 0:\n",
        "    return input_length // batch_size\n",
        "  else:\n",
        "    return input_length // batch_size + 1"
      ],
      "metadata": {
        "id": "0N7MCCfO-WF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "#model = GPT2Model.from_pretrained(\"gpt2\")\n",
        "model1 = model_new\n",
        "text = df['text'].tolist()\n",
        "print(len(text))\n",
        "batch_size = 36\n",
        "\n",
        "featuresds = np.zeros((len(text), 768))\n",
        "# print(\"featuresds\",featuresds)\n",
        "print(\"compute_number_batches(len(text), batch_size)\",compute_number_batches(len(text), batch_size))\n",
        "for batch in range(compute_number_batches(len(text), batch_size)):\n",
        "  print('Printing batch n. {} of {}'.format(batch + 1, compute_number_batches(len(text), batch_size)))\n",
        "  # fixed_text1=''.join(text[batch*batch_size : (batch+1)*batch_size])\n",
        "  # fixed_text1=fixed_text1.lower().split()\n",
        "  inputs = tokenizer(text[batch*batch_size : (batch+1)*batch_size], padding='max_length', max_length=30, truncation=True, return_tensors=\"pt\")\n",
        "  print(inputs)\n",
        "\n",
        "  mask = inputs['attention_mask'].cpu()\n",
        "  input_id = inputs[\"input_ids\"].squeeze(1).cpu()\n",
        "  # outputs = model1(input_id, mask)\n",
        "  print(mask.shape)\n",
        "  print(input_id.shape)\n",
        "  break\n",
        "  # last_hidden_states = outputs.last_hidden_state\n",
        "  # sentemb = last_hidden_states.detach().numpy()[:,last_hidden_states.shape[1]-1]\n",
        "  # featuresds[batch * batch_size: (batch + 1)* batch_size] = sentemb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v_4OjfzNHjN",
        "outputId": "81918000-5e6d-4f72-8cc4-e8960152f310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2016\n",
            "compute_number_batches(len(text), batch_size) 56\n",
            "Printing batch n. 1 of 56\n",
            "{'input_ids': tensor([[50256, 50256, 50256,  ...,  5509,   764,   220],\n",
            "        [50256, 50256, 50256,  ...,   262,  2240,   764],\n",
            "        [50256,   464,  9546,  ..., 10086,  4583,   764],\n",
            "        ...,\n",
            "        [50256, 50256, 50256,  ..., 42922,   764,   220],\n",
            "        [50256, 50256, 50256,  ...,  2746, 32808,   764],\n",
            "        [50256, 50256, 50256,  ...,    66, 39975,   764]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 1, 1,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1]])}\n",
            "torch.Size([36, 30])\n",
            "torch.Size([36, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2016%36"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpJw2KEdPtbd",
        "outputId": "2bf632c8-61f5-4f2e-b151-0b2d93d8ed88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KhJPNi2VPu7K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}